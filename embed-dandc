#!/usr/local/bin/python3

import sys
import os 
import json
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.schema import Document

def load_json_file(file_path):
 with open(file_path, 'r') as file:
  return json.load(file)

vectorstore = Chroma(embedding_function=OpenAIEmbeddings(),persist_directory="scriptures_db")

def embed(json_file_path):
 data = load_json_file(json_file_path)
 documents = []
 for section in data["sections"]:
  for verse in section["verses"]:
   documents.append(Document(
   page_content = verse["text"],
   metadata = {
     "title": data["title"],
     "section": section["section"],
     "verse": verse["verse"],
     "reference": verse["reference"]
   }
  ))

 batch_size = 5000 
 batches = [documents[i:i+batch_size] for i in range(0, len(documents), batch_size)]
 for batch in batches:
  vectorstore.add_documents(batch)

if __name__ == "__main__":
 embed('doctrine-and-covenants.json')

